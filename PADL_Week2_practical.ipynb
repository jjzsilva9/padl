{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjzsilva9/padl/blob/main/PADL_Week2_practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA2xDK4uX_dj"
      },
      "source": [
        "#PADL Practical 1: Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViXjsMPFYIju"
      },
      "source": [
        "##Linear regression in scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PEB5zeoyNdZ"
      },
      "source": [
        "We'll be using [scikit-learn](https://scikit-learn.org/stable/), [NumPy](https://numpy.org) and [matplotlib](https://matplotlib.org/). You can expect to be consulting the documentation on these libraries on a regular basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8zhGk9k8jzs"
      },
      "source": [
        "Begin by reading the scikit-learn [introduction to linear regression](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)  (up to and including Section 1.1.1 on Ordinary Least Squares). Note the comment on feature independence vs. multicollinearity, then try to run the following 4 lines of code copied from that page:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzSMa9CG-CTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "dd06ec7e-5bef-400d-eba5-e399d05dc6f7"
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Eu80TvjAbYY"
      },
      "source": [
        "The two arguments of reg.fit() describe three data points in terms of the values of a pair of independent ('input') variables, and the corresponding target values (the 'output'). Can you identify which is which?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKxlr3ao-J22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c7ca6a-4d8f-4204-9653-080c8ffe527a"
      },
      "source": [
        "reg.coef_"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 0.5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu1l3LY3CKl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed002dd-286e-48fb-ccf6-42e280d04eaa"
      },
      "source": [
        "reg.intercept_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1102230246251565e-16"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHCFKc5aBxCp"
      },
      "source": [
        "The above 2 lines of code display between them the 3 coefficients you need to define the output as a linear function of the two input variables.\n",
        "\n",
        "*   Can you now spell out the linear function y=f(x1,x2)?\n",
        "*   Is it possible to simplify f(**x**), and if so, how and why?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yawluXYqH-Zm"
      },
      "source": [
        "Now we'll move on to another example borrowed the scikit-learn web site (along with some of the text).\n",
        "The example below uses only the first feature of the **diabetes** dataset, in order to illustrate the data points within the two-dimensional plot. The straight line can be seen in the plot, showing how linear regression attempts to draw a straight line that will best minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation.\n",
        "\n",
        "The coefficients, residual sum of squares and the coefficient of determination are also calculated.\n",
        "\n",
        "Read through the code and comments to understand what it does. This may take a while. Here is a hint:\n",
        "\n",
        " **diabetes_X = diabetes.data[:, np.newaxis, 2]**\n",
        "\n",
        "What we are doing here is selecting every row of **diabetes.data** using “**:**” but only the values from the column with index 2. Without the **np.newaxis** we would end up with a vector (since a single column has one dimension), but we want a matrix. The **np.newaxis** achieves this. You can add a line **print(diabetes_X.shape)** to see the number of rows and columns of the resulting matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9WhM9Ult8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "92014f67-ccf7-4310-bb31-58f4fa44bb2f"
      },
      "source": [
        "# This line is needed to use matplotlib in Jupyter notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "# Use only one feature\n",
        "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-20]\n",
        "diabetes_X_test = diabetes_X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes_y[:-20]\n",
        "diabetes_y_test = diabetes_y[-20:]\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f'\n",
        "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
        "# The coefficient of determination:\n",
        "#   1 is perfect prediction\n",
        "#   0 is as good as always predicting the mean output value (using the training data).\n",
        "#   negative values are for a model that is worse than just predicting the mean.\n",
        "print('Coefficient of determination: %.2f'\n",
        "      % r2_score(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
        "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " [938.23786125]\n",
            "Mean squared error: 2548.07\n",
            "Coefficient of determination: 0.47\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAH9tJREFUeJzt3X+MHOV9x/HPeACTBN+ZNhFe32y7hERNKqOQNK0KyaS3CMW0SQvdbNVwrSgQKS2pyF6qVElLlNKWqir0x22iokQpJSnC10jLOGoFmKTiNl1qQvODSlAldUjO4W69DoXiuyMx2J6b/jGs7bvz+Wb2ZnZ253m//om8nufuq8jcfO75zvMdKwiCQAAAwFhbsi4AAABkizAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAY7pwoFy0vL+vQoUPatm2bLMtKuyYAAJCAIAi0tLSknTt3asuW9X//jxQGDh06pGKxmFhxAACgf+bm5uQ4zrp/HykMbNu27eQXGxkZSaYyAACQqsXFRRWLxZP38fVECgPd1sDIyAhhAACAIbNRi58HCAEAMBxhAAAAwxEGAAAwHGEAAADDEQYAADAcYQAAAMMRBgAAMBxhAAAAwxEGAAAwXKQJhAAAIHm+76vVaqnT6ahQKMh1Xdm23fc6CAMAAGTA8zzVajXNz8+f/MxxHNXrdVUqlb7WQpsAAIA+8zxP1Wp1RRCQpHa7rWq1Ks/z+loPYQAAgD7yfV+1Wk1BEKz5u+5nk5OT8n2/bzURBgAA6KNWq7VmR+B0QRBobm5OrVarbzURBgAA6KNOp5PodUkgDAAA0EeFQiHR65JAGAAAoI9c15XjOLIs64x/b1mWisWiXNftW02EAQAA+si2bdXrdUlaEwi6f56amurrvAHCAAAAfVapVNRoNDQ2Nrbic8dx1Gg0+j5nwArOdLZhlcXFRY2OjmphYUEjIyP9qAsAgNxLewJh1Ps3EwgBAMiIbdsaHx/PugzaBAAAmI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAACA4QgDAAAYjjAAAIDhCAMAABiOMAAAgOEIAwAAGI4wAABAxo4dy/b7EwYAAMjA/Lx08cWSZUlbt4b/+9xz2dRCGAAAQJLv+2o2m5qenlaz2ZTv+6l8n4ceCm/8xaJ08ODKv/u1X0vlW26IMAAAMJ7neSqVSiqXy5qYmFC5XFapVJLneYl8/eVl6Y/+KAwBv/Ir61/3qlcl8u1is4IgCDa6aHFxUaOjo1pYWNDIyEg/6gIAoC88z1O1WtXq26FlWZKkRqOhSqXS09d+/nnp6qulb3wj2vXPPiu97nU9faszinr/ZmcAAGAs3/dVq9XWBAFJJz+bnJyM3TJ47LFwF+C1r40WBG6/Pdw9SDIIxEEYAAAYq9VqaX5+ft2/D4JAc3NzarVaG36tIJD+5m/CEHDFFdG+f7MZrrv11nBdVs7J7lsDAJCtTqez6etefFH6jd+Q9u2L9j137ZL+7d+kiy6Kdn0/sDMAADBWoVDo+br//u/wSOC2bdGCQK0mnTghPfnkYAUBiTAAADCY67pyHOfkw4KrWZalYrEo13VPfvaFL4Rb+rt2RRsWtHdv2AqYmpJsO6HCE0YYAAAYy7Zt1et1SVoTCLp/npqaku/buv76MATccMPGX3fHDun73w9DwLXXJlx0CggDAACjVSoVNRoNjY2NrfjccRzdddcDuuWWirZule69d+Ov9Vu/Jb30ktTphNMFhwVzBgAAUHjMsNVqqdPpaHZ2l2699dLIa+++W7rpphSL61HU+zenCQAAkCTZuuWWcT31VMSrbemJJ6RLo2eGgUWbAABgtIMHw2cBzjlHkYLAu98tLS6GJwPyEAQkwgAAwFD33ReGgKi9/TvuCKcEPvxweJwwT2gTAACMEQTSe98rPfhg9DWtlvTOd6ZX0yAgDAAAcu+55+LP/f/BD6Sf+ql06hk0tAkAALn15S+HrYCoQeCtbw2fBQgCc4KARBgAgNT4vq9ms6np6Wk1m83Yb75D7z70oTAE7N4d7fq/+7swAHzrW4M7JTBNtAkAIAWe56lWq614I57jOKrX66pUKhlWll8/+pF04YXS8ePR1zz5ZDhW2HTsDABAwjzPU7VaXfNq3Ha7rWq1Ks/zMqosn775zXAX4IILogWBCy+Ujh4NdwIIAiHCAAAkyPd91Wo1nWm4a/ezyclJWgYJ+Iu/CEPA298e7fo//MMwAPzf/0nnn59ubcOGNgEAJKjVaq3ZEThdEASam5tTq9XS+Ph4/wrLiePHpTe/Wfre96Kv+epXpXe9K72a8oAwAAAJ6nQ6iV6H0NNPS298Y7w1L7wgbd+eSjm5Q5sAABJUKBQSvc5099wTtgKiBoH3vz9sBQQBQSAOdgYAIEGu68pxHLXb7TM+N2BZlhzHkeu6GVQ3HIJAuuoq6ZFHoq+5/36JQxq9Y2cAABJk27bq9bqk8MZ/uu6fp6amZJt4mH0DP/xhuAuwZUv0IDA/H4YHgsDmEAYAIGGVSkWNRkNjY2MrPnccR41GgzkDqzzwQBgCduyIdv0VV0i+H4aAVf8Xo0dWcKZ9rFUWFxc1OjqqhYUFjYyM9KMuABh6vu+r1Wqp0+moUCjIdV12BE5z443S5z8f/fq77pJuvjm1cnIp6v2bZwYAICW2bXN8cJWlJSnu75Tf/rb0pjelUw9CtAkAAKn72tfCVkDUILBzp/Tyy2ErgCCQPsIAACA1n/xkGAIuvzza9Z/4RBgA2m3pvPPSrQ2n0CYAACTq2DHp4oulQ4eir9m/P3pgQPIIAwCARHznO+Go4DgWF6Vt29KpB9HRJgAAbMpnPhO2AqIGgd/5nVNTAgkCg4GdAQBAbMvL0jvfKT32WPQ1//qv0nvfm15N6B1hAAAQ2aFD8Qf9HD4sXXRROvUgGbQJAAAb2rs3bAVEDQLlcrh7EAQEgWFAGAAArOu668IQEHWC8t13hwHgkUfCdRgOtAkAACscOSJdeGG8NQcORH/NMAYPOwMAAEnS5z4X/jYfNQhcckk4UyAICALDjjAAAIYbGwtDwAc/GO36228PA8DTT0vnnptubegP2gQAYKBeXhj09a9Lb397OvUgW+wMAIBBHnoo3guDzj1XevHFcCeAIJBf7AwAgAF275a+/OXo12/dKr30Unr1YLCwMwAAOXXiRLgLYFnRg8Add4S7AAQBs7AzAAA588QT0tveFm/N974nvf716dSDwcfOAADkRK0W7gLECQLdKYEEAbOxMwAAQywIpC0xf6374Aelz342nXownAgDADCEnnlG+umfjrfm8celX/iFdOrBcKNNAABD5FOfClsBcYLAyy+HOwgEAayHnQEAGAIjI+GgoKhcV/r3f0+vHuQLOwMAMKCOHDl1NDBqEPjSl8JdAIIA4mBnAAAGzN690V8Z3HXkiDQ6mko5MABhAAAGxDveIe3fH/367dulF15IrRwYhDYBAGTo2LFTrYCoQeDTnw5bAQQBJIWdAQDIwNe+Jl1+ebw1zzwjFYvp1AOzsTMAAH30gQ+EuwBxgkB3SiBBAGkhDABAyoLgVCvgH/8x2pqPfCRc110LpIk2AQCkpJcXBj3xhHTZZamUA6yLMAAACbvuOumf/znemuPHpXP4iYyM8E8PABISdzv/6qulhx5KpxYgDp4ZAIBNaLdPPQ8Q1b594bMABAEMCsIAAPTg9tvDAOA40dcsLYUhYPfu9OoCekGbAABi6OXJ/iBIvg4gSewM9Mj3fTWbTU1PT6vZbMr3/axLApCSF1+M3wr46EdPHQ0EBh07Az3wPE+1Wk3z8/MnP3McR/V6XZW4bxcBMLC++EXp/e+Pt+bpp6VLLkmnHiAthIGYPM9TtVpVsCrut9ttVatVNRoNAgEw5C66SHr22Xhr2AHAMKNNEIPv+6rVamuCgKSTn01OTtIyAIaQ759qBUQNAu9+N60A5ANhIIZWq7WiNbBaEASam5tTq9XqY1UANuOxx8IAEGfgz6OPhgHg4YfTqwvoJ9oEMXQ6nUSvA5Cd97xHevDBeGtOnJBsO516gCwRBmIoFAqJXgcg5Pu+Wq2WOp2OCoWCXNeVndJdN+7RwO3bpRdeSKUUYGDQJojBdV05jiNrnZ8mlmWpWCzKdd0+VwYML8/zVCqVVC6XNTExoXK5rFKpJM/zEvseBw/GPxp4331hK4AgABMQBmKwbVv1el2S1gSC7p+npqZS+40GyJvu6ZzVz+J0T+dsNhB8/ONhALj44uhrulMCJyY29a2BoWIFZ3o0fpXFxUWNjo5qYWFBIyMj/ahroJ1pzkCxWNTU1BTHCoGIfN9XqVRa96Fcy7LkOI5mZ2djB2ymBAKhqPdvdgZ6UKlUdPDgQc3MzGjPnj2amZnR7OwsQQCIIenTOQsL8VsBt93G0UBA4gHCntm2rfHx8azLAIZWUqdz7rlHuummeN/7mWekYjHeGiDPCAMAMrHZ0zlbt0rHjsX7nuwAAGdGmwBAJno5nXP8+KlWQNQg8L730QqIg5ewmYkwACATcU7nNJthADjvvOhf/xvfCANAo5FUxfnXj2OeGEyEAQCZqVQqajQaGhsbW/G54zhqNBr627+tyLKkcjn61/T9MAT83M8lXGzOpX3ME4ONo4UAMnf6BMIdOwq68srxWOtLJWl2NpXSjJDmMU9kK+r9mwcIAWTOtm0VCuOxdgAkae9e6dprUynJKHGOeXKKKp8IAwAydeWV0sxMvDU//rH0qlelU4+JeAkbCAMAMsGUwMHBS9jAA4QA+qbTiT8l8M47ORqYNl7CBsIAgNR97GNhANi5M/qaTicMAB/9aHp1IcRL2EAYAJCa7i7AHXdEX9PdBdixI726sNZGxzx590q+cbQQQKKOHpVe/ep4a972Numb30ynHsRz+jHPQqEg13XZERhiHC0E0Ff33itdf328Nfv3S5dfnk496A0vYTMTYQDApvRyKmB5ubd1ANJBGAAQWxBIW3p44ogTAcBg4gFCAJHt3x/+Rh8nCNx7L0cDgUHHzgCADdl2uLUfx9Gj0vnnp1MPgGQRBgCsiymBgBloEwBY4cCB+FMCP/YxWgHAMGNnAIAk6eqrpYcfjrem02E4EJAHhAHAcLQCANAmAAy0sBC/FVAo0AoA8oowABjkttvCALB9e/Q1jz4aBoBDh9KqCkDWaBMABmBKIICzYWcAyCnfj98KkE61AggCgDkIA0DOeF54Iz8nxr7f5z7H8wCAyWgTADnRy2/yL70kbd2afC0AhgthABhyHA0EsFm0CQzi+76azaamp6fVbDbl+37WJaFHX/96/OcBbr6ZVgCAM2NnwBCe56lWq2l+fv7kZ47jqF6vq1KpZFgZ4rjwQunIkXhrDh+WLroolXIA5AQ7AwbwPE/VanVFEJCkdrutarUqz/MyqgxRdXcB4gSB7i4AQQDARggDOef7vmq1moIz7A13P5ucnKRlMIAOH47fCti1i1YAgPgIAznXarXW7AicLggCzc3NqdVq9bEqnM1v/mYYAAqF6Gu6UwKffDK9ugDkF88M5Fyn00n0OqSHUwEAssLOQM4VIv56GfU6JOvYsc1NCQSAJBAGcs51XTmOI2udu41lWSoWi3Jdt8+Vma1eDwNAnIE/n/kMIQBAOmgT5Jxt26rX66pWq7Isa8WDhN2AMDU1Jdu2syrRKL20Ao4fjzdaGADiYmfAAJVKRY1GQ2NjYys+dxxHjUaDOQN9sJlWAEEAQNqs4ExnzlZZXFzU6OioFhYWNDIy0o+6kALf99VqtdTpdFQoFOS6LjsCKZqZka68Mt6aG26Q7rknlXIAGCjq/ZvfOQxi27bGx8ezLiP3emkF/O//Sq99bfK1AEAUhAEgIRwNBDCseGYA2IQf/CD+8wCOw6kAAIOFMAD04KqrwgBQKkVf88QTYQCYm0utLADoCW0CIAZaAQDyiJ0BYAM//jFTAgHkG2EAWMef/VkYAF7zmuhr9uwhBAAYPrQJgFV6aQX4vrSFaA1gSBEGAIW/yfdyM2cHAEAe8LsMjPaVr4Q7AXGCwEc+QisAQL6wMwAjjY5Ki4vx1iwsSEzjBpBHhAEYhaOBALAWbQLk3ve/H/9o4FvfSisAgDkIA8ita68NA8All0Rf853vhAHgW99KrSwAGDi0CZA7vbQC9uyZVqFQ0Bve4Eritc4AzMLOAHJhaSl+K+CCC47JcYqSLE1MTKhcLqtUKsnzvNTqBIBBRBjAUPvLvwwDQJyn/B95RLr/fk8/+tH5mp+fX/F37XZb1WqVQADAKFYQbPyI1OLiokZHR7WwsKARzlZhAPTSClheDtf5vq9SqbQmCJz62pYcx9Hs7Kxsm5YBgOEV9f7NzgCGRvdm3usLg7rrWq3WukEgvD7Q3NycWq3WJqoFgOFBGMDAe+CB8EYe55f0v//79Y8GdjqdSF8j6nUAMOw4TYCB1Usr4OhR6fzzz35NoVCI9LWiXgcAw46dAQyczbQCNgoCkuS6rhzHkbXON7EsS8ViUa7rxisCAIYUYQAD4dvfjh8CbrqptymBtm2rXq9L0ppA0P3z1NQUDw8CMAZhAJn6pV8KA8DP/mz0Ne12GADuvrv371upVNRoNDQ2Nrbic8dx1Gg0VKlUev/iADBkOFqITAzKC4N831er1VKn01GhUJDruuwIAMiNqPdvHiBE37zwgvQTPxFvzRveIH33u+nUI4Utg/Hx8fS+AQAMAdoESN0f/3G4ExAnCDz+eLgTkGYQAACE2BlAagalFQAAODt2BpCoEyc2dzQQANB/hAEk4otfDAPAuedGX/NP/0QIAIBBQJsAsZ3+BP7ExHWx1x87Fi80AADSRRhALJ7nqVaraX5+LvZadgAAYDDRJkBkf/3Xj+h976vECgJ/8Ae0AgBg0LEzgA1deqn01FOSdGXkNc89J/3kT6ZWEgAgQewMYF3dUwFhEIhmZqapICAIAMAwIQxghR/+sJejgV+TZEmy1Ol00ikMAJAawgAkSR/6UBgAduyIs2qXwhBw+clPCoVCwpUBANLGMwOG62VKYBgAVn8dS47jyHXdTdcEAOgvdgYMdPx4b1MC77/fk2VtkbVqYffPU1NTvPEPAIYQYcAgzWYYAM47L/qavXtPHQ2sVCpqNBoaGxtbcY3jOGo0GqpUKskWDADoCysINj4BHvV9yBhMris9+mi8Nb4vbVknKp4+gbBQKMh1XXYEAGAARb1/88xATgXB+jfzjdZtxLZtjY+Px//iGFoEQCDfaBPkzIEDYSsgThD40z9lSiDW53meSqWSyuWyJiYmVC6XVSqV5Hle1qUBSAhhICc+/OEwBPzMz0Rfs7QUBoBPfjK9ujDcPM9TtVrV/Pz8is/b7baq1SqBAMgJnhkYcr0cDWQHAFH4vq9SqbQmCHR1j5POzs7SMgAGVNT7NzsDQ+j55+MfDbzzTloBiKfVaq0bBCQpCALNzc2p1Wr1sSoAaeABwiFy113S7/9+vDWdTtypgkAo6mhpRlADw48wMARoBSALUUdLM4IaGH60CQbUyy/HbwXccAOtACTHdV05jrNm4mSXZVkqFouMoAZygDAwYPbtCwPA+edHX/Pkk2EAuOee9OqCeWzbVr1elyRGUAM5RxgYEJddFoaAX/7l6GuWl8MQsGtXamXlnu/7ajabmp6eVrPZlO/7WZc0UBhBDZiBo4UZ6mVK4FveIv3Xf6VSjnE8z1OtVlvxxLzjOKrX69zkVmECITCcot6/CQMZeOop6dJL463Zt0/avTudekzUHaaz+p9/d/ub33oB5AFzBgbQjTeGrYA4QeDll8MdBIJAcnzfV61WWxMEJJ38bHJykpYBAGNwtLAPOBo4WOIM0+GFTABMwM5ASg4fjn808K67OBrYDwzTAYCVCAMJu/POMADEmcPy/PNhALj55vTqwikM0wGAlWgTJIRWwPDoDtNpt9tnfG6g+wIehukAMAU7A5tw9Gj8VsAtt9AKyBrDdABgJcJADx57LAwAr3519DUHDoQB4FOfSq8uRMcwHQA4hTkDMdx4o/T5z8dbs7zcWwsB/cEwHQB5FvX+zTMDG+hlSuC73iV99avp1INk2bbN8UEAxqNNsI7vfjf8jT5OEGg2w/BAEAAADBN2BlZ58EHpPe+Jt+bECcnUnWW22QFg+LEz8IoPfCDcCYgaBK655tSpAFPvfZ7nqVQqqVwua2JiQuVyWaVSSZ7nZV0aACAGo3cGlpakuM9DfuUr0lVXpVPPMFnvRT/tdlvVapUn8gFgiBi5M/D44+EuQJwg8OKL4S4AQYAX/QBA3hgVBm67LQwBv/iL0a6/9dZTrYDXvCbV0vrO9301m01NT0+r2WzGunHHedEPAGDw5b5NcOyYdMkl0lnuXWv8x39IV1yRXk1Z8zxPtVptxQ3dcRzV6/VIW/u86AcA8iW3OwP/8z/hLsDWrdGDwMJCuAuQ9yBQrVbX/Gbf7fVHefiPF/0AQL7kLgx89rNhCHjTm6Jdf/31p1oBeR+umFSvv/uin9Vz/bssy1KxWORFPwAwJHIRBpaXpXe8IwwBv/d70db8y7+EAeALX0i3tkGSVK+fF/0AQL4MdRg4dCgMALYt7d8fbU2nE4aAX/3VdGsbREn2+nnRDwDkx1A+QPilL0m//uvRrx8flx55hBcGJd3rr1Qquuaaa5hACABDbqjeWvjbvy3dd1/06//hH8LJggj5vq9SqaR2u33G5wYsy5LjOJqdneWGDgA5kJu3Fi4sSNu3x1tz4ID0xjemUs5Q6/b6q9WqLMtaEQjo9QOAuQb2mYFHHw239aMGgde/PpwpEAQEgbOh1w8AWG3g2gQf/7j0V38V/fo//3PpE59Ir5684m2DAJB/Q9UmePllaWxMev756Gv+8z+ln//59GrKO9u2NT4+nnUZAIABkGkYOHxYevObpSNHol1v2+G1F1yQZlUAAJgls2cGOh3pLW+JFgR+93fDZwFOnCAIAACQtMx2BjxPevbZs1+zb5+0e3d/6gEAwFSZhYGzzbV59lnpda/rXy0AAJgsszbBNddIf/In0mWXhX/+8IfDdwwEAUEAAIB+GrijhQAAIBlR798DO3QIAAD0B2EAAADDEQYAADAcYQAAAMMRBgAAMBxhAAAAww3Ei4oGDW/0AwCYhDCwiud5qtVqmp+fP/mZ4ziq1+uqVCoZVgYAQDpoE5zG8zxVq9UVQUCS2u22qtWqPM/LqDIAANJDGHiF7/uq1Wo600DG7meTk5Pyfb/fpQEAkCrCwCtardaaHYHTBUGgubk5tVqtPlYFAED6CAOv6HQ6iV4HAMCwIAy8onC2dyr3cB0AAMOC0wSvcF1XjuOo3W6f8bkBy7LkOI5c182gOiAZHJsFcCbsDLzCtm3V63VJ4Y3/dN0/T01N8YMzIt/31Ww2NT09rWazyYOXA8DzPJVKJZXLZU1MTKhcLqtUKnFKBgBh4HSVSkWNRkNjY2MrPnccR41GgzkDEXHTGTwcmwVwNlZwpj3xVRYXFzU6OqqFhQWNjIz0o65MsZXau+5NZ/U/q+7uCqGq/3zfV6lUWve0TLcFNjs7y79zIGei3r8JA0hM2jcdQlpvms2myuXyhtfNzMxofHw8/YIA9E3U+zdtAiQmzVkNtB56x7FZABshDCAxad106HdvDsdmAWyEMIDEpHHTYUz05nWPza4+JdNlWZaKxSLHZgGDEQaQmDRuOoyJ3jyOzQLYCGEAiUnjpkO/OxkcmwVwNoQBJCrpmw797uRUKhUdPHhQMzMz2rNnj2ZmZjQ7O0sQAMDRQqQjqWOA3eOKG42J5ow8AKwV9f7NuwmQCtu2Ezmz3m09VKtVWZa1IhDQ7waAZAxMm4BZ9lgP/W4ASNdAtAk8z1OtVlvx1LjjOKrX6/ygx0lMIASAeIZmHDGz7AEASMdQjCNmoAwAANnLNAwwUAYAgOxlGgYYKAMAQPYyDQMMlAEAIHuZhgFeoAIAQPYyDQO8QAUAgOxlPnSIgTIAAGQr8zkDXQyUAeLjvxsAZzMU7ybgBxnQOyZ3AkhKZm0Cz/NUKpVULpc1MTGhcrmsUqkkz/OyKgkYGt3JnavndLTbbVWrVf47AhBLJm0CRhADveu+1nm9gV281hlA18COI2YEMbA5TO4EkLS+hwF+kAGbw+ROAEnrexjgBxmwOUzuBJC0vocBfpABm8PkTgBJ63sY4AcZsDlM7gSQtL6HAX6QAZvH5E4AScpsAuGZBqYUi0VNTU3xgwyIiMFdAM4m6v0703HE/CADACA9QzGO2LZtjY+PZ1kCAADGy/ythQAAIFuEAQAADEcYAADAcIQBAAAMRxgAAMBwhAEAAAxHGAAAwHCEAQAADEcYAADAcJEmEHYnFi8uLqZaDAAASE73vr3RmwcihYGlpSVJ4YuEAADAcFlaWtLo6Oi6fx/pRUXLy8s6dOiQtm3btua1wwAAYDAFQaClpSXt3LlTW7as/2RApDAAAADyiwcIAQAwHGEAAADDEQYAADAcYQAAAMMRBgAAMBxhAAAAwxEGAAAw3P8DElpXk810dYAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1glGYOMmWx"
      },
      "source": [
        "**Different train/test splits**\n",
        "\n",
        "The example you have downloaded reserves 20 datapoints for testing. Alter the example so that 10, 20, 40, 100 and 200 datapoints are put aside for testing (so 5 different training data sets are used in turn). Do the R-squared values improve as more data is kept for training?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OunDpHYsHFKV"
      },
      "source": [
        "##Linear regression in PyTorch\n",
        "\n",
        "The linear regression object `linear_model.LinearRegression` in the code above contains an implementation (in the `fit` method) of classical ordinary least squares. When we call `regr.fit(diabetes_X_train, diabetes_y_train)`, it constructs a set of linear equations in matrix form and then solves them using a closed form solution derived from linear algebra (in fact, it just calls `scipy.linalg.lstsq`).\n",
        "\n",
        "If linear regression (i.e. fitting a linear model with a least squares loss function) is all you want to do, then this is the right way to implement it. It's fast and it guarantees finding the global optimum. But what if you decide you'd like to introduce a nonlinearity into the model when you see it doesn't fit the data very well? Or you decide you'd like to replace sum of squared errors with a different loss function? Maybe something more robust to outliers? The problem is that these variations probably don't have closed form solutions and, if they do, will be very complicated to derive by hand. If you give up on finding a closed form solution and decide to fit the model using gradient descent, you're going to have to compute the derivatives yourself by hand. This is a nightmare!\n",
        "\n",
        "So, as we did in practical 0, let's see how we can re-implement linear regression using differentiable programming giving us a foundation that could easily be extended to a more complicated model or loss function with barely any extra work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZdF2wVIHBsu"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Convert dataset to PyTorch tensors\n",
        "# Note: Default floating point dtype in PyTorch is torch.float32 so we'll convert\n",
        "X_train_tensor = torch.from_numpy(np.float32(diabetes_X_train))\n",
        "Y_train_tensor = torch.from_numpy(np.float32(diabetes_y_train)).unsqueeze(1)\n",
        "X_test_tensor = torch.from_numpy(np.float32(diabetes_X_test))\n",
        "Y_test_tensor = torch.from_numpy(np.float32(diabetes_y_test)).unsqueeze(1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfQmyLuRI-1c"
      },
      "source": [
        "As usual, we import torch and convert our data into PyTorch tensors. By default, every layer in PyTorch operates on 32 bit floats, so we convert to that for ease. The `unsqueeze` operation is just to make the Y values have the same size as the Xs (the Xs are size $n\\times 1$ whereas the Ys are just $n$ - the unsqueeze adds the singleton dimension on the end). This is really unimportant (I call it \"tensor origami\") but you'll get an error without it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq0Qr2fBJmOv"
      },
      "source": [
        "###A minimal implementation\n",
        "\n",
        "We're going to start with a minimal implementation that looks quite like practical 0. Then we'll do it again in a more flexible form that is generally better for building large, complex models in PyTorch.\n",
        "\n",
        "Let's start by defining the components of our model. We're going to do this using PyTorch *layers*. These are the basic building blocks of \"computational graphs\" - i.e. series of computations through which tensors containing data will be passed and which backpropagation can be automatically applied to. The built in layers in PyTorch are defined in `torch.nn`. In this case, we just want a single `Linear` layer that takes one input ($x$) and provides one output ($y$) which is computed via the linear function: $y=ax+b$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8NfNguCusFi"
      },
      "source": [
        "linear = torch.nn.Linear(1, 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86tJCzfavMjv"
      },
      "source": [
        "This has created an instance of the Linear layer with its own parameters ($a$ and $b$ in the equation above) that by default have `requires_grad` set to True (i.e. they will be updated, or learnt, if we start doing optimisation through the layer). By default, the parameters are initialised randomly. We can inspect their initial values ($a$ is called `weight` and $b$ is called `bias`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFsxSdjVviF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1c60eb-0d59-4f16-cb47-bc083207f5c1"
      },
      "source": [
        "print('Weight: %.2f'% linear.weight)\n",
        "print('Bias: %.2f'% linear.bias)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight: -0.35\n",
            "Bias: -0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLfvB1-rvxIc"
      },
      "source": [
        "We're now ready to set up the optimiser. Here, we will use the `parameters` method of the linear layer which returns a list of its optimisable parameters. Also, I have set the learning rate to a value that works ok for this data (i.e. I did the tuning for you - this is a skill you will need to develop later)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cINY5IAvwDTh"
      },
      "source": [
        "optim = torch.optim.SGD(linear.parameters(), lr=0.6)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPsi6WsQwR8V"
      },
      "source": [
        "Now it's time to set up our main training loop and run the optimisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlJ8n8NOwRF6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36ae223-343d-4186-d2bc-b838000ba7b5"
      },
      "source": [
        "epochs = 2000\n",
        "for epoch in range(epochs):\n",
        "    # Pass the training x values through the linear layer to get y predictions\n",
        "    y_predict = linear(X_train_tensor)\n",
        "    # Compute the loss as mean squared error between predictions and given y\n",
        "    loss = ((y_predict-Y_train_tensor)**2.0).mean()\n",
        "    # Reset the gradients to zero\n",
        "    optim.zero_grad()\n",
        "    # Back propagate from the loss through the layers\n",
        "    loss.backward()\n",
        "    # Take a gradient descent step\n",
        "    optim.step()\n",
        "    if not epoch % 200:\n",
        "        # Print out the loss every 200 iterations\n",
        "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 29610.796875\n",
            "epoch 200, loss 4626.68017578125\n",
            "epoch 400, loss 4181.1796875\n",
            "epoch 600, loss 4031.17138671875\n",
            "epoch 800, loss 3980.6611328125\n",
            "epoch 1000, loss 3963.65380859375\n",
            "epoch 1200, loss 3957.927490234375\n",
            "epoch 1400, loss 3955.9990234375\n",
            "epoch 1600, loss 3955.349609375\n",
            "epoch 1800, loss 3955.131591796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkW0ElaYw9u7"
      },
      "source": [
        "First let's verify that the optimisation has indeed updated the parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XktGAUYnxCFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03458ab7-89d7-483d-ba8b-9e8680d287b4"
      },
      "source": [
        "print('Weight: %.2f'% linear.weight)\n",
        "print('Bias: %.2f'% linear.bias)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight: 934.18\n",
            "Bias: 152.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3thN9EkzxEc4"
      },
      "source": [
        "The weight should now be very similar to the result from the closed form solution above. Let's check that the error on the predictions is also similar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFicphZYxN1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8feadc8-78b1-41ef-9e4f-6eae4819ffc6"
      },
      "source": [
        "y_predict = linear(X_test_tensor)\n",
        "loss = ((y_predict-Y_test_tensor)**2.0).mean()\n",
        "print('Mean squared error: %.2f'% loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 2552.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQnGLLB0aM02"
      },
      "source": [
        "###A more PyTorch solution\n",
        "\n",
        "Let's see a slightly different version of the same thing above:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM4pdsbxaL2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a161376-687f-45ec-e716-8882d42efe7e"
      },
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        # Call superclass constructor\n",
        "        super(linearRegression, self).__init__()\n",
        "        # Initialise contents of model - in this case a single linear layer\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the model is simply application of linear layer\n",
        "        y = self.linear(x)\n",
        "        return y\n",
        "\n",
        "# Instantiate model\n",
        "model = linearRegression(1,1)\n",
        "# Instantiate loss function\n",
        "criterion = torch.nn.MSELoss()\n",
        "# Setup optimiser\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.6)\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(epochs):\n",
        "    y_predict = model(X_train_tensor)\n",
        "    loss = criterion(y_predict,Y_train_tensor)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    if not epoch % 200:\n",
        "        # Print out the loss every 200 iterations\n",
        "        print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "y_predict = model(X_test_tensor)\n",
        "loss = criterion(y_predict,Y_test_tensor)\n",
        "print('Mean squared error: %.2f'% loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 29193.787109375\n",
            "epoch 200, loss 4626.1357421875\n",
            "epoch 400, loss 4180.99560546875\n",
            "epoch 600, loss 4031.109619140625\n",
            "epoch 800, loss 3980.64013671875\n",
            "epoch 1000, loss 3963.646728515625\n",
            "epoch 1200, loss 3957.9248046875\n",
            "epoch 1400, loss 3955.998046875\n",
            "epoch 1600, loss 3955.34912109375\n",
            "epoch 1800, loss 3955.131103515625\n",
            "Mean squared error: 2552.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krGomu1FoXkl"
      },
      "source": [
        "There are only two differences:\n",
        "1. We put the linear layer inside a `torch.nn.Module` object. This is a neat container for the layers in a model but it has many other benefits that we'll see later. For example, note that this object also has a `parameters()` method which returns a list of all trainable parameters of all layers within the model. You can see that if the model had a more complex structure with many layers, this would be preferable over having to call `parameters()` on every layer and putting them all in a list when setting up the optimiser.\n",
        "2. We used a built in layer for the mean squared error loss, `torch.nn.MSELoss()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hipMhTTR9W17"
      },
      "source": [
        "###Exercises\n",
        "\n",
        "1. Introduce an outlier into the training set. i.e. add an extra data point to `X_train_tensor` and `Y_train_tensor` where the x value is similar to the other training data but the y value is orders of magnitudes bigger.\n",
        "2. Re-run the linear least squares code as above. Add code to plot the data without the outlier and the line of best fit. How bad is the fit including the outlier?\n",
        "3. Can a different loss function provide robustness to outliers? Take a look at [pytorch.org/docs/stable/nn.html#loss-functions](https://pytorch.org/docs/stable/nn.html#loss-functions) to see the built in loss functions available. L1 (absolute errors rather than squared errors) should be less sensitive to extreme values. Give it a try."
      ]
    }
  ]
}